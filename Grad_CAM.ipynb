{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AaPG3bMO7ATwl6yfSUgO_HelLmGdqnlc",
      "authorship_tag": "ABX9TyMpnoyxKp13HZttwVP+OsD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tharushaliyanagama/OralCancerEarlyDetection-DSGP/blob/Image-Prediction-and-XAI/Grad_CAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pst6KtdM2YV8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from typing import Tuple, List\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class_names = ['cancer', 'non-cancer', 'leukoplakia']"
      ],
      "metadata": {
        "id": "WKlbLe-l2dQS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "Ay3EQyJN2fGq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "def load_model(model_path: str, num_classes: int = 3) -> nn.Module:\n",
        "    \"\"\"Load the trained ResNet50 model with correct number of classes\"\"\"\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    # Load state dict with strict=False to handle size mismatches\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Handle size mismatches for fc layer\n",
        "    if 'fc.weight' in state_dict and state_dict['fc.weight'].shape[0] != num_classes:\n",
        "        print(f\"Warning: Number of classes in model ({state_dict['fc.weight'].shape[0]}) doesn't match expected ({num_classes})\")\n",
        "        del state_dict['fc.weight']\n",
        "        del state_dict['fc.bias']\n",
        "\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rA5Xtfa42isV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM implementation\n",
        "class GradCAM:\n",
        "    def __init__(self, model: nn.Module, target_layer: nn.Module):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        # Register hooks\n",
        "        self.target_layer.register_forward_hook(self.save_activation)\n",
        "        self.target_layer.register_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)\n",
        "\n",
        "    def backward(self, outputs: torch.Tensor, class_idx: int):\n",
        "        outputs[:, class_idx].sum().backward(retain_graph=True)\n",
        "\n",
        "    def generate(self, x: torch.Tensor, class_idx: int) -> np.ndarray:\n",
        "        # Forward pass\n",
        "        self.model.zero_grad()\n",
        "        output = self.forward(x)\n",
        "\n",
        "        # Backward pass for specific class\n",
        "        self.backward(output, class_idx)\n",
        "\n",
        "        # Pool the gradients and calculate weights\n",
        "        pooled_gradients = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
        "\n",
        "        # Weight the activations\n",
        "        weighted_activations = pooled_gradients * self.activations\n",
        "        heatmap = torch.mean(weighted_activations, dim=1).squeeze()\n",
        "        heatmap = torch.relu(heatmap)  # Apply ReLU\n",
        "\n",
        "        # Normalize heatmap\n",
        "        heatmap /= torch.max(heatmap)\n",
        "        heatmap = heatmap.cpu().numpy()\n",
        "\n",
        "        return heatmap"
      ],
      "metadata": {
        "id": "x50iz9Ai3DIv"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}