{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AaPG3bMO7ATwl6yfSUgO_HelLmGdqnlc",
      "authorship_tag": "ABX9TyOvL9YM9o3US/MQMxhPeDlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tharushaliyanagama/OralCancerEarlyDetection-DSGP/blob/Image-Prediction-and-XAI/Grad_CAM_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pst6KtdM2YV8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from typing import Tuple, List\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class_names = ['cancer', 'non-cancer', 'leukoplakia']"
      ],
      "metadata": {
        "id": "WKlbLe-l2dQS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "Ay3EQyJN2fGq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "def load_model(model_path: str, num_classes: int = 3) -> nn.Module:\n",
        "    \"\"\"Load the trained ResNet50 model with correct number of classes\"\"\"\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    # Load state dict with strict=False to handle size mismatches\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Handle size mismatches for fc layer\n",
        "    if 'fc.weight' in state_dict and state_dict['fc.weight'].shape[0] != num_classes:\n",
        "        print(f\"Warning: Number of classes in model ({state_dict['fc.weight'].shape[0]}) doesn't match expected ({num_classes})\")\n",
        "        del state_dict['fc.weight']\n",
        "        del state_dict['fc.bias']\n",
        "\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rA5Xtfa42isV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM implementation\n",
        "class GradCAM:\n",
        "    def __init__(self, model: nn.Module, target_layer: nn.Module):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        # Register hooks\n",
        "        self.target_layer.register_forward_hook(self.save_activation)\n",
        "        self.target_layer.register_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)\n",
        "\n",
        "    def backward(self, outputs: torch.Tensor, class_idx: int):\n",
        "        outputs[:, class_idx].sum().backward(retain_graph=True)\n",
        "\n",
        "    def generate(self, x: torch.Tensor, class_idx: int) -> np.ndarray:\n",
        "        # Forward pass\n",
        "        self.model.zero_grad()\n",
        "        output = self.forward(x)\n",
        "\n",
        "        # Backward pass for specific class\n",
        "        self.backward(output, class_idx)\n",
        "\n",
        "        # Pool the gradients and calculate weights\n",
        "        pooled_gradients = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
        "\n",
        "        # Weight the activations\n",
        "        weighted_activations = pooled_gradients * self.activations\n",
        "        heatmap = torch.mean(weighted_activations, dim=1).squeeze()\n",
        "        heatmap = torch.relu(heatmap)  # Apply ReLU\n",
        "\n",
        "        # Normalize heatmap\n",
        "        heatmap /= torch.max(heatmap)\n",
        "        heatmap = heatmap.cpu().numpy()\n",
        "\n",
        "        return heatmap"
      ],
      "metadata": {
        "id": "x50iz9Ai3DIv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_heatmap(heatmap: np.ndarray, image: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
        "    \"\"\"Apply heatmap to original image\"\"\"\n",
        "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap * alpha + image * (1 - alpha)\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
        "    return superimposed_img\n",
        "\n",
        "def load_and_preprocess_image(image_path: str) -> Tuple[torch.Tensor, np.ndarray]:\n",
        "    \"\"\"Load and preprocess image for model input\"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    original_image = np.array(image)\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    return input_tensor, original_image"
      ],
      "metadata": {
        "id": "5qtazJH25n5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_image(model: nn.Module, image_path: str):\n",
        "    \"\"\"Analyze an image and generate visualization and explanation\"\"\"\n",
        "    # Initialize Grad-CAM (targeting the last convolutional layer)\n",
        "    target_layer = model.layer4[-1].conv3\n",
        "    grad_cam = GradCAM(model, target_layer)\n",
        "\n",
        "    # Load and preprocess image\n",
        "    input_tensor, original_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        confidence, pred_idx = torch.max(probabilities, 1)\n",
        "        confidence = confidence.item() * 100\n",
        "        pred_class = class_names[pred_idx.item()]\n",
        "\n",
        "    # Generate heatmap\n",
        "    heatmap = grad_cam.generate(input_tensor, pred_idx.item())\n",
        "\n",
        "    # Apply heatmap to original image\n",
        "    heatmap_img = apply_heatmap(heatmap, original_image)\n",
        "\n",
        "    # Generate explanation\n",
        "    top_features = [\"Lesion border irregularity\", \"Color variation\", \"Surface texture\", \"Contrast with surrounding tissue\"]\n",
        "    explanation = generate_explanation(pred_class, confidence, top_features)\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original_image)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(heatmap, cmap='jet')\n",
        "    plt.title('Activation Heatmap')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Overlay\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(heatmap_img)\n",
        "    plt.title(f'Prediction: {pred_class}\\nConfidence: {confidence:.1f}%')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print explanation\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DIAGNOSTIC EXPLANATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(explanation)\n",
        "    print(\"=\"*80 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "IR2m2HjN5p9o"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}